{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yx_f8UkXKYCN",
    "outputId": "ca755b0e-9238-4e2d-93d3-c910694dfbf1"
   },
   "outputs": [],
   "source": [
    "!pip install mord\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRJyWSYCzrBA"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMYnd1y1Fnm4",
    "outputId": "79418ee2-f396-46ad-a689-71b25f5a38fe"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip /content/drive/MyDrive/CS229/7606611.zip -d cs229-data\n",
    "!unzip cs229-data/SubjData.zip -d cs229-data/SubjData\n",
    "!unzip cs229-data/P80.zip -d cs229-data/P80\n",
    "for i in range(8):\n",
    "  for j in range(10):\n",
    "    !unzip cs229-data/P{i}{j}.zip -d cs229-data/P{i}{j}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vULBO-ePacjB",
    "outputId": "a9bfdf50-d343-4594-9007-19d7adbead31"
   },
   "outputs": [],
   "source": [
    "!rm cs229-data/SubjData.zip\n",
    "!rm cs229-data/P80.zip\n",
    "for i in range(8):\n",
    "  for j in range(10):\n",
    "    !rm cs229-data/P{i}{j}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNDAWlBcz3Uv"
   },
   "source": [
    "**Code Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ysc3mlOI2rH7"
   },
   "outputs": [],
   "source": [
    "import pytz\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DEFAULT_TZ = pytz.FixedOffset(540)  # GMT+09:00; Asia/Seoul\n",
    "\n",
    "PATH_DATA = 'cs229-data/SubjData/'\n",
    "PATH_ESM = os.path.join(PATH_DATA, 'EsmResponse.csv')\n",
    "PATH_PARTICIPANT = os.path.join(PATH_DATA, 'UserInfo.csv')\n",
    "\n",
    "PATH_INTERMEDIATE = './intermediate'\n",
    "\n",
    "SECOND_MS = 1000\n",
    "MINUTE_MS = 60*SECOND_MS\n",
    "DATA_TYPES = {\n",
    "    'Acceleration': 'ACC',\n",
    "    'AmbientLight': 'AML',\n",
    "    'Calorie': 'CAL',\n",
    "    'Distance': 'DST',\n",
    "    'EDA': 'EDA',\n",
    "    'HR': 'HRT',\n",
    "    'RRI': 'RRI',\n",
    "    'SkinTemperature': 'SKT',\n",
    "    'StepCount': 'STP',\n",
    "    'UltraViolet': 'ULV',\n",
    "    'ActivityEvent': 'ACE',\n",
    "    'ActivityTransition': 'ACT',\n",
    "    'AppUsageEvent': 'APP',\n",
    "    'BatteryEvent': 'BAT',\n",
    "    'CallEvent': 'CAE',\n",
    "    'Connectivity': 'CON',\n",
    "    'DataTraffic': 'DAT',\n",
    "    'InstalledApp': 'INS',\n",
    "    'Location': 'LOC',\n",
    "    'MediaEvent': 'MED',\n",
    "    'MessageEvent': 'MSG',\n",
    "    'WiFi': 'WIF',\n",
    "    'ScreenEvent': 'SCR',\n",
    "    'RingerModeEvent': 'RNG',\n",
    "    'ChargeEvent': 'CHG',\n",
    "    'PowerSaveEvent': 'PWS',\n",
    "    'OnOffEvent': 'ONF'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFgCX43p1GBG"
   },
   "source": [
    "**Read in emotional response data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rkW2Rwbebgu0",
    "outputId": "b4248e94-33fb-454f-eeb3-ce94bfa12d00"
   },
   "outputs": [],
   "source": [
    "esm_response = pd.read_csv('cs229-data/SubjData/EsmResponse.csv')\n",
    "esm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8R5KRKZhSte"
   },
   "outputs": [],
   "source": [
    "def remove_mul_deltas(df):\n",
    "  for column in df.columns:\n",
    "    if column.count(\"-\") > 1:\n",
    "        if column in df.columns:\n",
    "          df = df.drop(column, axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lcNt07y1Kjb"
   },
   "source": [
    "**Read in sensor data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CM55om9Db36o"
   },
   "outputs": [],
   "source": [
    "pcodes = [f\"P{str(i).zfill(2)}\" for i in range(81)]\n",
    "all_data_df = pd.DataFrame()\n",
    "for pcode in pcodes:\n",
    "  user_df = pd.DataFrame()\n",
    "\n",
    "  for datatype in [\"HR\", \"SkinTemperature\", \"Acceleration\", \"AmbientLight\"]: # only uses these two sensor datas for now\n",
    "    try:\n",
    "      df = pd.read_csv(f\"cs229-data/{pcode}/{datatype}.csv\")\n",
    "    except FileNotFoundError:\n",
    "      continue\n",
    "\n",
    "    df['pcode'] = pcode\n",
    "\n",
    "    df[\"timestamp-1min\"] = df[\"timestamp\"] - MINUTE_MS\n",
    "    df = pd.merge_asof(df, df[df.columns.difference(['pcode', \"timestamp-1min\"])], left_on=\"timestamp-1min\", right_on=\"timestamp\", suffixes=[\"\", \"-1min\"], direction=\"nearest\", tolerance=1500)\n",
    "    df = remove_mul_deltas(df)\n",
    "    df = df.drop(\"timestamp-1min\", axis=1)\n",
    "\n",
    "    df[\"timestamp-5min\"] = df[\"timestamp\"] - 5*MINUTE_MS\n",
    "    df = pd.merge_asof(df, df[df.columns.difference(['pcode', \"timestamp-5min\"])], left_on=\"timestamp-5min\", right_on=\"timestamp\", suffixes=[\"\", \"-5min\"], direction=\"nearest\", tolerance=1500)\n",
    "    df = remove_mul_deltas(df)\n",
    "    df = df.drop(\"timestamp-5min\", axis=1)\n",
    "\n",
    "    df[\"timestamp-10min\"] = df[\"timestamp\"] - 10*MINUTE_MS\n",
    "    df = pd.merge_asof(df, df[df.columns.difference(['pcode', \"timestamp-10min\"])], left_on=\"timestamp-10min\", right_on=\"timestamp\", suffixes=[\"\", \"-10min\"], direction=\"nearest\", tolerance=1500)\n",
    "    df = remove_mul_deltas(df)\n",
    "    df = df.drop(\"timestamp-10min\", axis=1)\n",
    "\n",
    "    if user_df.empty:\n",
    "        user_df = df\n",
    "    else:\n",
    "        user_df = pd.merge_asof(user_df, df, on=[\"timestamp\"], by=[\"pcode\"], direction=\"nearest\", tolerance=1500)\n",
    "        # user_df = pd.merge(\n",
    "        #   user_df,\n",
    "        #   df,\n",
    "        #   how=\"inner\",\n",
    "        #   on=['pcode', 'timestamp'],\n",
    "        # )\n",
    "        user_df = user_df.dropna()\n",
    "\n",
    "    # all_data_df.isnull().mean() * 100\n",
    "    all_data_df = pd.concat([all_data_df, user_df])\n",
    "    all_data_df = all_data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xAX7saw2El3s",
    "outputId": "f1de974f-7ede-4118-c393-de5e52036fd9"
   },
   "outputs": [],
   "source": [
    "all_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRkNzVGf0-SY"
   },
   "source": [
    "**Join Sensor Data with Emotional Response Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TZz8CK-VgJ7J"
   },
   "outputs": [],
   "source": [
    "joined_df = pd.merge(\n",
    "          all_data_df,\n",
    "          esm_response,\n",
    "          how=\"inner\",\n",
    "          left_on=['pcode'],\n",
    "          right_on=['pcode']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZPKj6hjZgOVk"
   },
   "outputs": [],
   "source": [
    "threshold = 60000 # questionare completed within a minute of sensor readings\n",
    "joined_df = joined_df[abs(joined_df['timestamp'] - joined_df['responseTime']) <= threshold]\n",
    "df = joined_df.reset_index(drop=True)\n",
    "df = df.drop(columns=['timestamp', 'responseTime', 'scheduledTime', 'duration', 'disturbance', 'change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "48u5kxHdmKaH",
    "outputId": "8b32588e-db79-484c-d19f-3547bb227e6a"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBZgWBCrykTm"
   },
   "source": [
    "**Calculate total acceleration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "irfpwW1AwqwK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[\"accel\"] = np.sqrt(df[\"x\"] ** 2 + df[\"y\"] ** 2 + df[\"z\"] ** 2)\n",
    "df[\"accel-1min\"] = np.sqrt(df[\"x-1min\"] ** 2 + df[\"y-1min\"] ** 2 + df[\"z-1min\"] ** 2)\n",
    "df[\"accel-5min\"] = np.sqrt(df[\"x-5min\"] ** 2 + df[\"y-5min\"] ** 2 + df[\"z-5min\"] ** 2)\n",
    "df[\"accel-10min\"] = np.sqrt(df[\"x-10min\"] ** 2 + df[\"y-10min\"] ** 2 + df[\"z-10min\"] ** 2)\n",
    "df = df.drop(columns=['x', 'y', 'z', 'x-1min', 'y-1min', 'z-1min', 'x-5min', 'y-5min', 'z-5min', 'x-10min', 'y-10min', 'z-10min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65k4wgypx0ke"
   },
   "source": [
    "**Shuffle Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2h2_JBsRw6Iy"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chpbh2WQ1PPU"
   },
   "source": [
    "**Split into train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "vHSzuXmhRKYj",
    "outputId": "998de694-93e8-4ae1-9ad2-51be976989c3"
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "seventy_pct = int(df.shape[0] * 0.7)\n",
    "\n",
    "train_set = df.loc[:seventy_pct, :]\n",
    "test_set = df.loc[seventy_pct:, :]\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78IPgTbdf8FF"
   },
   "outputs": [],
   "source": [
    "columns_to_split = ['bpm', 'temperature']\n",
    "\n",
    "# Create the first DataFrame with the specified columns\n",
    "x_train = train_set[columns_to_split]\n",
    "x_test = test_set[columns_to_split]\n",
    "\n",
    "# Create the second DataFrame with the remaining columns\n",
    "y_train = train_set.drop(columns_to_split, axis=1)\n",
    "y_test = test_set.drop(columns_to_split, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NOLbzkcec2y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mord import LogisticIT  # LogisticIT is for immediate-threshold ordinal regression\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xr2rOp9PgRMR",
    "outputId": "995891a9-46eb-422c-cde6-24acefbfbc3c"
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "predictions = {}\n",
    "softmax_mses = {}\n",
    "softmax_errors = {}\n",
    "\n",
    "# Train a model for each output (valence, arousal, attention, stress)\n",
    "for i, target in enumerate(['valence', 'arousal', 'attention', 'stress']):\n",
    "    # Create and train the ordinal regression model\n",
    "    ordinal_model = LogisticIT()\n",
    "    ordinal_model.fit(x_train, y_train[target])\n",
    "\n",
    "    models[target] = ordinal_model\n",
    "\n",
    "    test_preds = ordinal_model.predict(x_test)\n",
    "    predictions[target] = test_preds\n",
    "\n",
    "    train_preds = ordinal_model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train[target], train_preds)\n",
    "    train_error = 1 - accuracy_score(y_train[target], train_preds)\n",
    "    test_mse = mean_squared_error(y_test[target], predictions[target])\n",
    "    test_error = 1 - accuracy_score(y_test[target], predictions[target])\n",
    "    softmax_errors[target] = train_error\n",
    "    softmax_mses[target] = train_mse\n",
    "    print(f\"\\nMetrics for {target}:\")\n",
    "    print(f\"Train MSE: {train_mse:.4f}\")\n",
    "    print(f\"Train error: {train_error:.2f}\")\n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Test error: {test_error:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "_-G2nkp1zV3a",
    "outputId": "837a14e8-d4a0-4111-c9e5-1e8efb0179c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import 2\n",
    "\n",
    "models = {}\n",
    "predictions = {}\n",
    "forest_errors = {}\n",
    "forest_mses = {}\n",
    "# Train a model for each output (valence, arousal, attention, stress)\n",
    "for i, target in enumerate(['valence', 'arousal', 'attention', 'stress']):\n",
    "    # Create and train the ordinal regression model\n",
    "    ordinal_model = RandomForestClassifier()\n",
    "    ordinal_model.fit(x_train, y_train[target])\n",
    "\n",
    "    models[target] = ordinal_model\n",
    "\n",
    "    test_preds = ordinal_model.predict(x_test)\n",
    "    predictions[target] = test_preds\n",
    "\n",
    "    train_preds = ordinal_model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train[target], train_preds)\n",
    "    train_error = 1 - accuracy_score(y_train[target], train_preds)\n",
    "    test_mse = mean_squared_error(y_test[target], predictions[target])\n",
    "    test_error = 1 - accuracy_score(y_test[target], predictions[target])\n",
    "    forest_errors[target] = train_error\n",
    "    forest_mses[target] = train_mse\n",
    "    print(f\"\\nMetrics for {target}:\")\n",
    "    print(f\"Train MSE: {train_mse:.4f}\")\n",
    "    print(f\"Train error: {train_error:.2f}\")\n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Test error: {test_error:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "-RpUXhCo5FOt",
    "outputId": "e60e4b59-e197-4e8a-ae3f-b82e9a0bb531"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "models = list(forest_mses.keys())\n",
    "mse_random_forest = [forest_errors[x] for x in models]\n",
    "mse_softmax = [softmax_errors[x] for x in models]\n",
    "\n",
    "# X-axis positions\n",
    "x = np.arange(len(models))\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.35\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Bars\n",
    "rf_bars = ax.bar(x - bar_width/2, mse_random_forest, bar_width, label='Random Forest', color='skyblue')\n",
    "softmax_bars = ax.bar(x + bar_width/2, mse_softmax, bar_width, label='Softmax Regression', color='salmon')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('MSE Error')\n",
    "ax.set_title('MSE Error by Model and Algorithm')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "# Add values on top of bars\n",
    "for bars in [rf_bars, softmax_bars]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # Offset text slightly above the bar\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDqflYIf2IxL",
    "outputId": "adf84f9c-28fb-4f6f-b4a5-fa6ed0bd3cf0"
   },
   "outputs": [],
   "source": [
    "# Convert x_train and y_train to numpy arrays\n",
    "x_trainnp = x_train.to_numpy()\n",
    "y_cols = ['valence', 'arousal', 'attention', 'stress']\n",
    "y_filtered = y_train.loc[:,y_cols]\n",
    "y_trainnp = y_filtered.to_numpy()\n",
    "# Convert x_test and y_test to numpy arrays\n",
    "x_testnp = x_test.to_numpy()\n",
    "y_filtered = y_test.loc[:,y_cols]\n",
    "y_testnp = y_filtered.to_numpy()\n",
    "print(x_testnp.shape)\n",
    "print(y_testnp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7EQ1XN37iii"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred, tolerance=0):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of predictions within a tolerance for each column.\n",
    "\n",
    "    Args:\n",
    "        y_true: True target values.\n",
    "        y_pred: Predicted target values.\n",
    "        tolerance: Maximum allowed difference between true and predicted values.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with accuracy for each column and the overall accuracy.\n",
    "    \"\"\"\n",
    "    print(y_pred)\n",
    "    within_tolerance = np.abs(y_true - y_pred) <= tolerance\n",
    "    print(within_tolerance)\n",
    "    column_accuracies = np.mean(within_tolerance, axis=0)  # Accuracy for each column\n",
    "    overall_accuracy = np.mean(within_tolerance)  # Overall accuracy\n",
    "    return {\n",
    "        \"valence_accuracy\": column_accuracies[0],\n",
    "        \"arousal_accuracy\": column_accuracies[1],\n",
    "        \"attention_accuracy\": column_accuracies[2],\n",
    "        \"stress_accuracy\": column_accuracies[3],\n",
    "        \"overall_accuracy\": overall_accuracy\n",
    "    }\n",
    "\n",
    "def postprocess_predictions(predictions, min_val=-3, max_val=3):\n",
    "    \"\"\"\n",
    "    Rounds predictions to the nearest integer and clips them to a specified range.\n",
    "\n",
    "    Args:\n",
    "        predictions: Array of predicted values.\n",
    "        min_val: Minimum allowed value.\n",
    "        max_val: Maximum allowed value.\n",
    "\n",
    "    Returns:\n",
    "        Processed predictions as integers within the range [min_val, max_val].\n",
    "    \"\"\"\n",
    "    rounded = np.rint(predictions)  # Round to nearest integer\n",
    "    clipped = np.clip(rounded, min_val, max_val)  # Clip to range [-3, 3]\n",
    "    return clipped.astype(int)  # Ensure integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsoRMkE8LM2l",
    "outputId": "5e96c416-0458-4a7f-f9c0-401e538d1938"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(2,)),  # Input layer with 2 features\n",
    "    Dense(128, activation='relu'),                   # Hidden layer 1\n",
    "    Dense(64, activation='relu'),                    # Hidden layer 2\n",
    "    Dense(4, activation='linear')                    # Output layer for 4 targets\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x=x_trainnp, y=y_trainnp, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(x_testnp, y_testnp)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
    "\n",
    "# Calculate predictions\n",
    "train_predictions = model.predict(x_trainnp)\n",
    "test_predictions = model.predict(x_testnp)\n",
    "\n",
    "# Post-process predictions\n",
    "train_predictions_processed = postprocess_predictions(train_predictions)\n",
    "test_predictions_processed = postprocess_predictions(test_predictions)\n",
    "\n",
    "# Calculate accuracies using processed predictions\n",
    "train_accuracy = calculate_accuracy(y_trainnp, train_predictions_processed)\n",
    "test_accuracy = calculate_accuracy(y_testnp, test_predictions_processed)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Training Accuracy:\")\n",
    "for key, value in train_accuracy.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nTesting Accuracy:\")\n",
    "for key, value in test_accuracy.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQnHgUPv1aO8",
    "outputId": "f4a9700b-18b0-458e-9c3a-69d32896ff40"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5C5yEq62Evf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ZquMxtbFZJXO",
    "outputId": "33b75f6b-30bc-4fd3-e2b6-2671382ea6d9"
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "Tp4GrVXCZOFc",
    "outputId": "20bd2908-2a3f-4b61-8365-f869a81365ba"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
